{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a63856",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b29cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb4abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677906e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed991c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d8a712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x7df2d7f86900>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc6f698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "gemini_client = genai.Client(api_key=\"api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1499eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5f537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7c9949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    gemini_client = genai.Client(api_key=api_key)\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    return print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d38d86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7e74d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run kafka with Java, in the project directory, run:\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "\n",
      "To run kafka with Python, create a virtual environment and run requirements.txt and the python files in that environment.\n",
      "To create a virtual env and install packages (run only once):\n",
      "python -m venv env\n",
      "source env/bin/activate\n",
      "pip install -r ../requirements.txt\n",
      "To activate it (you'll need to run it every time you need the virtual env):\n",
      "source env/bin/activate\n",
      "To deactivate it:\n",
      "deactivate\n",
      "This works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate). Also, the virtual environment should be created only to run the python file, and Docker images should first all be up and running.\n",
      "\n",
      "If you encounter a \"ModuleNotFoundError: No module named 'kafka.vendor.six.moves'\" error, use pip install kafka-python-ng instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag('how do I run kafka?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0854e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ.get(\"GEMINI_KEY\"))  # Returns None if not set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag('the course has already started, can I still enroll?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd09ae0",
   "metadata": {},
   "source": [
    "### RAG with Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e315eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e68939d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the client and connect to our local instance\n",
    "qd_client = QdrantClient(\"http://localhost:6333\", timeout=60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59e5edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40129c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qd_client.delete_collection(collection_name=\"zoomcamp-faq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cb1c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new collection\n",
    "# qd_client.delete_collection(collection_name=collection_name) this is to delete if it exists and you dont want it\n",
    "# let me rather check for the collection \n",
    "\n",
    "collection_name = \"zoomcamp-faq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfa8454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'zoomcamp-faq' already exists\n"
     ]
    }
   ],
   "source": [
    "# Check if collection exists\n",
    "if not qd_client.collection_exists(collection_name):\n",
    "    # Create the collection if it doesn't exist\n",
    "    qd_client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "            distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "        )\n",
    "    )\n",
    "    print(f\"Collection '{collection_name}' created successfully\")\n",
    "else:\n",
    "    print(f\"Collection '{collection_name}' already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d99a40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb936678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npoints = []\\n\\nfor i, doc in enumerate(documents):\\n    text = doc['question'] + ' ' + doc['text']\\n    vector = models.Document(text=text, model=model_handle)\\n    point = models.PointStruct(\\n        id=i,\\n        vector=vector,\\n        payload=doc\\n    )\\n    points.append(point)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include the questions unlike earlier\n",
    "# switch to batch processing to see if terminal would stop crashing\n",
    "'''\n",
    "points = []\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06fca125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1c7289bf44409f87623b406521128a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080571549ee346229c813e9f73050e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/367 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54a67cd98fa496bb55b9c3ee0e49cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6e731c54384efb9a993513b0de1927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978bc9c0579a41319779a672936b0f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4ccb72d0de4ba28e876cb0609810e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/model.onnx:   0%|          | 0.00/130M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process in batches\n",
    "batch_size = 100\n",
    "points_batch = []\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload={\"question\": doc[\"question\"]}  # Minimal payload\n",
    "    )\n",
    "    points_batch.append(point)\n",
    "    if len(points_batch) >= batch_size:\n",
    "        qd_client.upsert(collection_name=collection_name, points=points_batch)\n",
    "        points_batch = []\n",
    "if points_batch:\n",
    "    qd_client.upsert(collection_name=collection_name, points=points_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b8f3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#points[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eee5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'I just discovered the course. Can I still join it?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be7ed05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(question):\n",
    "    print('vector_search is used')\n",
    "    \n",
    "    course = 'data-engineering-zoomcamp'\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=question,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        query_filter=models.Filter( \n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=5,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acdf1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0a56109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    gemini_client = genai.Client(api_key=api_key)\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    return print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fcab544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = vector_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fef45fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search is used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run kafka, use `docker ps` to confirm that your kafka broker docker container is working. If it is not working, navigate to the docker compose yaml file folder and run `docker compose up -d` to start all instances.\n",
      "\n",
      "To run producer/consumer/kstreams in the terminal, in the project directory, run: `java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java`.\n",
      "\n",
      "If you are running a producer.py file, create a virtual environment and run requirements.txt in that environment. Then activate the virtual environment.\n",
      "*   To create a virtual env and install packages (run only once):\n",
      "    `python -m venv env`\n",
      "    `source env/bin/activate`\n",
      "    `pip install -r ../requirements.txt`\n",
      "*   To activate it (you'll need to run it every time you need the virtual env):\n",
      "    `source env/bin/activate`\n",
      "*   To deactivate it:\n",
      "    `deactivate`\n"
     ]
    }
   ],
   "source": [
    "rag('how do I run kafka?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f02782",
   "metadata": {},
   "source": [
    "### Lessons learnt\n",
    "Due to persistence of the Docker container, I don't need to re-run the entire codes again. All I need is:\n",
    "\n",
    "- `docker ps -a`\n",
    "- `docker start containerID`\n",
    "- ensure the collection exists on qdrant dashboard and is healthy with points before proceeding with the next.\n",
    "- For quadrant \n",
    "    - initiate client, embed, collection name\n",
    "    - use the check code, \"if collecton exists\" skip\n",
    "    - move to questions, vector search, build_prompt, llm and the rag\n",
    "- if you proceed with recreating points and upsert, the kernel will crash."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
