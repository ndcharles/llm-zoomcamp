{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b0188c",
   "metadata": {},
   "source": [
    "## From RAG to Agents: Building Smart AI Assistants\n",
    "An attempt to recover my lost notes after Codespaces crashed on me ðŸ˜«\n",
    "\n",
    "### What is RAG?\n",
    "RAG (Retrieval-Augmented Generation) is a technique that combines retrieval of information with generation by a Large Language Model (LLM). It is particularly effective when you have a specific knowledge base and want the LLM to answer questions only using that context.\n",
    "\n",
    "RAG consists of 3 parts:\n",
    "- Search â†’ Finds relevant docs (e.g., FAQ entries about course enrollment).\n",
    "- Prompt â†’ Combines docs + query into a structured template.\n",
    "- LLM â†’ Generates a grounded answer (e.g., \"Yes, you can join late (see FAQ).\").\n",
    "\n",
    "### AI Agents\n",
    "These are autonomous systems that interact with environments, make decisions, and perform actions (e.g., search, answer, modify data). \n",
    "Agents are AI systems that can:\n",
    "\n",
    "- Make decisions about what actions to take\n",
    "- Use tools to accomplish tasks\n",
    "- Maintain state and context\n",
    "- Learn from previous interactions\n",
    "- Work towards specific goals\n",
    "\n",
    "Agentic flow is not necessarily a completely independent agent, but it can still make some decisions during the flow execution\n",
    "\n",
    "A typical agentic flow consists of:\n",
    "- Receiving a user request\n",
    "- Analyzing the request and available tools\n",
    "- Deciding on the next action\n",
    "- Executing the action using appropriate tools\n",
    "- Evaluating the results\n",
    "- Either completing the task or continuing with more actions\n",
    "\n",
    "The key difference from basic RAG is that agents can:\n",
    "- Make multiple search queries\n",
    "- Combine information from different sources\n",
    "- Decide when to stop searching\n",
    "- Use their own knowledge when appropriate\n",
    "- Chain multiple actions together\n",
    "\n",
    "So in agentic RAG, the system\n",
    "- has access to the history of previous actions\n",
    "- makes decisions independently based on the current information and the previous actions\n",
    "\n",
    "### Agentic RAG (Decision-Making)\n",
    "Agentic RAG enhances basic RAG by allowing the AI assistant to decide whether to answer a question directly using its own knowledge or to perform a search in the FAQ database. This is achieved by modifying the prompt to include instructions and output templates for different actions:\n",
    "\n",
    "- SEARCH: If the context is empty and the LLM decides it needs more information from the FAQ database\n",
    "- ANSWER (source: CONTEXT): If the LLM can answer the question using the provided context from a search\n",
    "- ANSWER (source: OWN_KNOWLEDGE): If the context does not contain the answer, or if the question can be answered without needing a search, the LLM uses its internal knowledge\n",
    "\n",
    "### Difference bbetween Basic RAG and Agentic RAG\n",
    "\n",
    "| Feature            | Basic RAG                          | Agentic RAG                          |\n",
    "|--------------------|------------------------------------|--------------------------------------|\n",
    "| **Decision-Making** | Always retrieves before answering  | Decides whether to retrieve (e.g., skips search for simple queries) |\n",
    "| **Flexibility**    | Linear flow (search â†’ prompt â†’ LLM) | Dynamic loops (iterative queries, multi-source combining) |\n",
    "| **Memory**         | No history of past actions         | Tracks previous searches/queries to avoid redundancy |\n",
    "| **Tool Use**       | Single retrieval tool              | Chains multiple tools (search + edit + APIs) |\n",
    "| **Autonomy**       | Follows fixed instructions         | Makes independent decisions (e.g., stops after max iterations) |\n",
    "\n",
    "\n",
    "\n",
    "### Agentic search\n",
    "Agentic search extends RAG with multi-query exploration and iterative refinement.\n",
    "\n",
    "**How it works:**\n",
    "- Reformulates queries (e.g., \"How to excel in Module 1?\" â†’ \"Docker best practices\").\n",
    "- Combines results from multiple searches.\n",
    "- Stops when sufficient context is gathered or max iterations reached.\n",
    "\n",
    "Advantage: Deeper topic coverage than single-query RAG.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b7e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the files and document needed\n",
    "\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681dc08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x72ea1642dd30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import minsearch, the toy search engine for this\n",
    "# use AppendableIndex instead of Index such that new documents can be added\n",
    "# Create the index\n",
    "# declare text fields, and the keywords field for search\n",
    "# fit the documents to the index\n",
    "\n",
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9845101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the search function with a boost param to ensure question is ranked high\n",
    "# Also add a filer for course to search\n",
    "# Declare the number of results to display\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd45b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c9a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our basic RAG prompt template \n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294a1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d1893c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada2efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
