{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b0188c",
   "metadata": {},
   "source": [
    "## From RAG to Agents: Building Smart AI Assistants\n",
    "An attempt to recover my lost notes after Codespaces crashed on me 😫\n",
    "\n",
    "### What is RAG?\n",
    "RAG (Retrieval-Augmented Generation) is a technique that combines retrieval of information with generation by a Large Language Model (LLM). It is particularly effective when you have a specific knowledge base and want the LLM to answer questions only using that context.\n",
    "\n",
    "RAG consists of 3 parts:\n",
    "- Search → Finds relevant docs (e.g., FAQ entries about course enrollment).\n",
    "- Prompt → Combines docs + query into a structured template.\n",
    "- LLM → Generates a grounded answer (e.g., \"Yes, you can join late (see FAQ).\").\n",
    "\n",
    "### AI Agents\n",
    "These are autonomous systems that interact with environments, make decisions, and perform actions (e.g., search, answer, modify data). \n",
    "Agents are AI systems that can:\n",
    "\n",
    "- Make decisions about what actions to take\n",
    "- Use tools to accomplish tasks\n",
    "- Maintain state and context\n",
    "- Learn from previous interactions\n",
    "- Work towards specific goals\n",
    "\n",
    "Agentic flow is not necessarily a completely independent agent, but it can still make some decisions during the flow execution\n",
    "\n",
    "A typical agentic flow consists of:\n",
    "- Receiving a user request\n",
    "- Analyzing the request and available tools\n",
    "- Deciding on the next action\n",
    "- Executing the action using appropriate tools\n",
    "- Evaluating the results\n",
    "- Either completing the task or continuing with more actions\n",
    "\n",
    "The key difference from basic RAG is that agents can:\n",
    "- Make multiple search queries\n",
    "- Combine information from different sources\n",
    "- Decide when to stop searching\n",
    "- Use their own knowledge when appropriate\n",
    "- Chain multiple actions together\n",
    "\n",
    "So in agentic RAG, the system\n",
    "- has access to the history of previous actions\n",
    "- makes decisions independently based on the current information and the previous actions\n",
    "\n",
    "### Agentic RAG (Decision-Making)\n",
    "Agentic RAG enhances basic RAG by allowing the AI assistant to decide whether to answer a question directly using its own knowledge or to perform a search in the FAQ database. This is achieved by modifying the prompt to include instructions and output templates for different actions:\n",
    "\n",
    "- SEARCH: If the context is empty and the LLM decides it needs more information from the FAQ database\n",
    "- ANSWER (source: CONTEXT): If the LLM can answer the question using the provided context from a search\n",
    "- ANSWER (source: OWN_KNOWLEDGE): If the context does not contain the answer, or if the question can be answered without needing a search, the LLM uses its internal knowledge\n",
    "\n",
    "### Difference bbetween Basic RAG and Agentic RAG\n",
    "\n",
    "| Feature            | Basic RAG                          | Agentic RAG                          |\n",
    "|--------------------|------------------------------------|--------------------------------------|\n",
    "| **Decision-Making** | Always retrieves before answering  | Decides whether to retrieve (e.g., skips search for simple queries) |\n",
    "| **Flexibility**    | Linear flow (search → prompt → LLM) | Dynamic loops (iterative queries, multi-source combining) |\n",
    "| **Memory**         | No history of past actions         | Tracks previous searches/queries to avoid redundancy |\n",
    "| **Tool Use**       | Single retrieval tool              | Chains multiple tools (search + edit + APIs) |\n",
    "| **Autonomy**       | Follows fixed instructions         | Makes independent decisions (e.g., stops after max iterations) |\n",
    "\n",
    "\n",
    "\n",
    "### Agentic search\n",
    "Agentic search extends RAG with multi-query exploration and iterative refinement.\n",
    "\n",
    "**How it works:**\n",
    "- Reformulates queries (e.g., \"How to excel in Module 1?\" → \"Docker best practices\").\n",
    "- Combines results from multiple searches.\n",
    "- Stops when sufficient context is gathered or max iterations reached.\n",
    "\n",
    "Advantage: Deeper topic coverage than single-query RAG.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b7e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the files and document needed\n",
    "\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681dc08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.append.AppendableIndex at 0x7848dd4c9a90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import minsearch, the toy search engine for this\n",
    "# use AppendableIndex instead of Index such that new documents can be added\n",
    "# Create the index\n",
    "# declare text fields, and the keywords field for search\n",
    "# fit the documents to the index\n",
    "\n",
    "from minsearch import AppendableIndex\n",
    "\n",
    "index = AppendableIndex(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9845101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the search function with a boost param to ensure question is ranked high\n",
    "# Also add a filer for course to search\n",
    "# Declare the number of results to display\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "        output_ids=True\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd45b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76c9a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our basic RAG prompt template \n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462d7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294a1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d1893c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = build_prompt(question, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dada2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97508dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f232b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "def llm(prompt):\n",
    "    gemini_client = genai.Client(api_key=api_key)\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt,\n",
    "        config={\n",
    "        \"response_mime_type\": \"application/json\"\n",
    "    }\n",
    "    )\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c27ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a847bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"answer\": \"Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8480bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8be73ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n \"answer\": \"Yes, even if you don\\'t register, you\\'re still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don\\'t leave everything for the last minute.\"\\n}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Asking a known answer\n",
    "rag(\"Can i still join the class?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14361c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I am sorry, but I cannot answer the question because the context is empty.\"'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Asking unknown to prove the efficiency of agentic RAG\n",
    "rag(\"How do I patch KDE under FreeBSD?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48db3c6",
   "metadata": {},
   "source": [
    "### \"Agentic\" RAG\n",
    "\n",
    "First, we'll take the prompt we have so far and make it a little more \"agentic\":\n",
    "\n",
    "- Tell the LLM that it can answer the question directly or look up context\n",
    "- Provide output templates\n",
    "- Show clearly what's the source of the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0f1145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are tooling the agent usign prompt which gives it multiple options\n",
    "# At the onset, the context is empty since there is no history. The LLM now lookuo the answer in the FAQ db\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "At the beginning the context is EMPTY.\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "If CONTEXT is EMPTY, you can use our FAQ database.\n",
    "In this case, use the following output template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\"\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "429a2548",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Can I still join the course?'\n",
    "context = 'EMPTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f55904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "804514f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "EMPTY\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9dfc1bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': 'The question asks about course enrollment, and without any context, I need to consult the FAQ database to find information on enrollment deadlines and procedures.'}\n"
     ]
    }
   ],
   "source": [
    "# By default Gemini displays the normal answer.\n",
    "# To get the JSOn such that I can get all the response objects, I have to add config param to the response template above.\n",
    "# now i can fetch the ACTION and REASONING as JSON response\n",
    "\n",
    "answer_json = llm(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4d767cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'SEARCH',\n",
       " 'reasoning': \"Since the context is empty, I don't have any information to determine if the student can join the course. I need to consult the FAQ or course information to find the answer.\"}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "answer = json.loads(answer_json)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0febb05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEARCH'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d51c1212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Since the context is empty, I don't have any information to determine if the student can join the course. I need to consult the FAQ or course information to find the answer.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer['reasoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92236647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the onset, the CONTEXT is empty. Now the LLM decides to check the FAQ DB\n",
    "# To add CONTEXT now, we build a context that includes the responses from the search we executed.\n",
    "# That is, Throw the question at the search engine, fetch the result and use it to build a CONTEXT\n",
    "\n",
    "def build_context(search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    return context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee5270e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_results below referes to the search fxn defines above to fetch results from our search engine\n",
    "# context = build a context based on the FAQ records fetched\n",
    "# Then build a final prompt which updates the prompt_template we defined above with the context gotten\n",
    "\n",
    "search_results = search(question)\n",
    "context = build_context(search_results)\n",
    "prompt = prompt_template.format(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62fad3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "At the beginning the context is EMPTY.\n",
      "\n",
      "<QUESTION>\n",
      "Can I still join the course?\n",
      "</QUESTION>\n",
      "\n",
      "<CONTEXT> \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
      "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
      "</CONTEXT>\n",
      "\n",
      "If CONTEXT is EMPTY, you can use our FAQ database.\n",
      "In this case, use the following output template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\"\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# See the updated prompt below which now has the initial prompt + the question + the context from previous step\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1d67b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
      "  \"source\": \"CONTEXT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "answer_json = llm(prompt)\n",
    "print(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f55b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making it a function\n",
    "# First attempt to answer it with our know knowledge\n",
    "# If needed, do the lookup and then answer\n",
    "\n",
    "def agentic_rag_v1(question):\n",
    "    context = \"EMPTY\"\n",
    "    prompt = prompt_template.format(question=question, context=context)\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(answer)\n",
    "\n",
    "    if answer['action'] == 'SEARCH':\n",
    "        print('need to perform search...')\n",
    "        search_results = search(question)\n",
    "        context = build_context(search_results)\n",
    "        \n",
    "        prompt = prompt_template.format(question=question, context=context)\n",
    "        answer_json = llm(prompt)\n",
    "        answer = json.loads(answer_json)\n",
    "        #print(answer)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ec6cce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action': 'SEARCH', 'reasoning': \"The question is about joining the course. Since I don't have any context, I should consult the FAQ database to see if there's information about course enrollment or registration.\"}\n",
      "need to perform search...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"Based on the provided context, here are a few ways to join the course:\\n\\n*   **Register before the course starts:** Use the registration link mentioned in the context.\\n*   **Join the Telegram channel:** Subscribe to the course's Telegram channel for announcements.\\n*   **Join the Slack channel:** Register in DataTalks.Club's Slack and join the dedicated channel for the course.\\n*   **Even if you don't register:** You are still eligible to submit the homeworks.\",\n",
       " 'source': 'CONTEXT'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing it on two questions\n",
    "agentic_rag_v1('how do I join the course?') #clearly in the KB, so it should fetch this from CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f07ef98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"To patch KDE under FreeBSD, you'll typically need to download the patch file (usually a `.diff` or `.patch` file), navigate to the KDE source directory, and then apply the patch using the `patch` command. Here's a general outline of the steps:\\n\\n1.  **Obtain the Patch:** Download the patch file from the source where it's provided (e.g., a bug report, a mailing list, or a software repository).\\n\\n2.  **Locate the KDE Source Directory:** You need to find where KDE is installed and where its source files are located. If you installed KDE via ports or packages, the source might not be readily available. You may need to download the source separately. If you built KDE from source, you already know the directory.\\n\\n3.  **Apply the Patch:** Open a terminal, navigate to the root directory of the KDE source tree, and use the `patch` command:\\n\\n    ```sh\\n    patch -p1 < /path/to/your/patchfile.patch\\n    ```\\n\\n    *   `-p1` tells patch to remove the first directory component from the filenames in the patch file. Adjust this number if the patch fails or if the directory structure in the patch file doesn't match your source tree.\\n    *   Replace `/path/to/your/patchfile.patch` with the actual path to the patch file.\\n\\n4.  **Recompile and Reinstall:** After applying the patch, you will need to recompile the affected KDE components and reinstall them. This usually involves using `make` followed by `make install` (or the appropriate build system commands for KDE).\\n\\n**Example:**\\n\\nLet's say you have a patch file named `kwin.patch` and your KDE source directory is `/usr/ports/x11/kde5/kwin/work/kwin-5.27.0`.\\n\\n```sh\\ncd /usr/ports/x11/kde5/kwin/work/kwin-5.27.0\\npatch -p1 < /path/to/kwin.patch\\nmake\\nmake install\\n```\\n\\n**Important Considerations:**\\n\\n*   **Backup:** Always back up the files you are patching before applying the patch. This allows you to revert the changes if something goes wrong.\\n*   **Permissions:** You might need root privileges (using `sudo`) to write to the KDE source directory and install the patched components.\\n*   **Conflicts:** If the patch fails to apply cleanly, it might be due to conflicts with other changes you've made or with updates to the source code. You will need to resolve these conflicts manually by editing the affected files.\\n*   **KDE Version:** Ensure that the patch is intended for the specific version of KDE you are using. Applying a patch designed for a different version can lead to errors or instability.\\n*   **Alternative methods:** If you are using a ports system, sometimes there is a patches directory within the port's directory where you can place the patch file. The build system will often automatically apply the patches found in that directory. Check the specific port's documentation.\\n\\nThis is a general guideline. The exact steps may vary depending on how you installed KDE and the specific nature of the patch.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second question\n",
    "agentic_rag_v1('how patch KDE under FreeBSD?') # this isnt in the KB, so it should answer it from its OWN_KNOWLEDGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d58438",
   "metadata": {},
   "source": [
    "### Agentic Search\n",
    "This is like agentic RAG but then we can perform multiple iterations. This is unlike the previous one where we did just SEARCH and ANSWER.\n",
    "This is like performing DEEP RESEARCH in LLMs\n",
    "\n",
    "Let's build a prompt:\n",
    "- List available actions:\n",
    "    - Search in FAQ\n",
    "    - Answer using own knowledge\n",
    "    - Answer using information extracted from FAQ\n",
    "- Provide access to the previous actions\n",
    "- Have clear stop criteria (no more than X iterations)\n",
    "- We also specify the output format, so it's easier to parse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9eaedfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup(seq):\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for el in seq:\n",
    "        _id = el['_id']\n",
    "        if _id in seen:\n",
    "            continue\n",
    "        seen.add(_id)\n",
    "        result.append(el)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60064bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant.\n",
    "\n",
    "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
    "\n",
    "The CONTEXT is build with the documents from our FAQ database.\n",
    "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
    "from FAQ to and add them to the context.\n",
    "PREVIOUS_ACTIONS contains the actions you already performed.\n",
    "\n",
    "At the beginning the CONTEXT is empty.\n",
    "\n",
    "You can perform the following actions:\n",
    "\n",
    "- Search in the FAQ database to get more data for the CONTEXT\n",
    "- Answer the question using the CONTEXT\n",
    "- Answer the question using your own knowledge\n",
    "\n",
    "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
    "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
    "\n",
    "Don't use search queries used at the previous iterations.\n",
    "\n",
    "Don't repeat previously performed actions.\n",
    "\n",
    "Don't perform more than {max_iterations} iterations for a given student question.\n",
    "The current iteration number: {iteration_number}. If we exceed the allowed number \n",
    "of iterations, give the best possible answer with the provided information.\n",
    "\n",
    "Output templates:\n",
    "\n",
    "If you want to perform search, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"SEARCH\",\n",
    "\"reasoning\": \"<add your reasoning here>\",\n",
    "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
    "}}\n",
    "\n",
    "If you can answer the QUESTION using CONTEXT, use this template:\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER_CONTEXT\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"CONTEXT\"\n",
    "}}\n",
    "\n",
    "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
    "\n",
    "{{\n",
    "\"action\": \"ANSWER\",\n",
    "\"answer\": \"<your answer>\",\n",
    "\"source\": \"OWN_KNOWLEDGE\"\n",
    "}}\n",
    "\n",
    "<QUESTION>\n",
    "{question}\n",
    "</QUESTION>\n",
    "\n",
    "<SEARCH_QUERIES>\n",
    "{search_queries}\n",
    "</SEARCH_QUERIES>\n",
    "\n",
    "<CONTEXT> \n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "<PREVIOUS_ACTIONS>\n",
    "{previous_actions}\n",
    "</PREVIOUS_ACTIONS>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2eafc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'how do I do well on module 1'\n",
    "max_iterations = 3\n",
    "iteration_number = 0\n",
    "search_queries = []\n",
    "search_results  = []\n",
    "previous_actions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9f615b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b03a59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)\n",
    "answer = json.loads(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "988f1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_actions.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea601dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = answer['keywords']\n",
    "\n",
    "for kw in keywords:\n",
    "    search_queries.append(kw)\n",
    "    sr = search(kw)\n",
    "    search_results.extend(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7d5d267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = dedup(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b2cdce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_number = 2\n",
    "\n",
    "context = build_context(search_results)\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    question=question,\n",
    "    context=context,\n",
    "    search_queries=\"\\n\".join(search_queries),\n",
    "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "    max_iterations=max_iterations,\n",
    "    iteration_number=iteration_number\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43fd6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_json = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b499b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION #0...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 0. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"SEARCH\",\n",
      "  \"reasoning\": \"The question is about succeeding in module 1, but I have no information about the specific requirements or content of the module. I need to search for information on how to succeed in the course, potentially including tips, resources, and expectations for students in module 1.\",\n",
      "  \"keywords\": [\n",
      "    \"how to succeed in module 1\",\n",
      "    \"module 1 tips\",\n",
      "    \"module 1 resources\",\n",
      "    \"expectations for module 1\",\n",
      "    \"course success strategies\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "ITERATION #1...\n",
      "You're a course teaching assistant.\n",
      "\n",
      "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
      "\n",
      "The CONTEXT is build with the documents from our FAQ database.\n",
      "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
      "from FAQ to and add them to the context.\n",
      "PREVIOUS_ACTIONS contains the actions you already performed.\n",
      "\n",
      "At the beginning the CONTEXT is empty.\n",
      "\n",
      "You can perform the following actions:\n",
      "\n",
      "- Search in the FAQ database to get more data for the CONTEXT\n",
      "- Answer the question using the CONTEXT\n",
      "- Answer the question using your own knowledge\n",
      "\n",
      "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
      "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic. \n",
      "\n",
      "Don't use search queries used at the previous iterations.\n",
      "\n",
      "Don't repeat previously performed actions.\n",
      "\n",
      "Don't perform more than 3 iterations for a given student question.\n",
      "The current iteration number: 1. If we exceed the allowed number \n",
      "of iterations, give the best possible answer with the provided information.\n",
      "\n",
      "Output templates:\n",
      "\n",
      "If you want to perform search, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"SEARCH\",\n",
      "\"reasoning\": \"<add your reasoning here>\",\n",
      "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
      "}\n",
      "\n",
      "If you can answer the QUESTION using CONTEXT, use this template:\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER_CONTEXT\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"CONTEXT\"\n",
      "}\n",
      "\n",
      "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
      "\n",
      "{\n",
      "\"action\": \"ANSWER\",\n",
      "\"answer\": \"<your answer>\",\n",
      "\"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n",
      "\n",
      "<QUESTION>\n",
      "what do I need to do to be successful at module 1?\n",
      "</QUESTION>\n",
      "\n",
      "<SEARCH_QUERIES>\n",
      "how to succeed in module 1\n",
      "module 1 resources\n",
      "course success strategies\n",
      "module 1 tips\n",
      "expectations for module 1\n",
      "</SEARCH_QUERIES>\n",
      "\n",
      "<CONTEXT> \n",
      "section: Module 5: pyspark\n",
      "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
      "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
      "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
      "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
      "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
      "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
      "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
      "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
      "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
      "\n",
      "section: Module 4: analytics engineering with dbt\n",
      "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
      "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
      "Solution:\n",
      "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
      "\n",
      "section: Module 5: pyspark\n",
      "question: Module Not Found Error in Jupyter Notebook .\n",
      "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
      "The solution which worked for me(use following in jupyter notebook) :\n",
      "!pip install findspark\n",
      "import findspark\n",
      "findspark.init()\n",
      "Thereafter , import pyspark and create spark contex<<t as usual\n",
      "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
      "Filter based on conditions based on multiple columns\n",
      "from pyspark.sql.functions import col\n",
      "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
      "Krishna Anand\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
      "answer: Issue:\n",
      "e…\n",
      "Solution:\n",
      "pip install psycopg2-binary\n",
      "If you already have it, you might need to update it:\n",
      "pip install psycopg2-binary --upgrade\n",
      "Other methods, if the above fails:\n",
      "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
      "First uninstall the psycopg package\n",
      "Then update conda or pip\n",
      "Then install psycopg again using pip.\n",
      "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
      "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
      "Solution:\n",
      "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
      "engine = create_engine(conn_string)\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
      "answer: Error raised during the jupyter notebook’s cell execution:\n",
      "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
      "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
      "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
      "\n",
      "section: Module 1: Docker and Terraform\n",
      "question: WSL - Insufficient system resources exist to complete the requested service.\n",
      "answer: Cause:\n",
      "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
      "Solution\n",
      "for updating Windows terminal which worked for me:\n",
      "Go to Microsoft Store.\n",
      "Go to the library of apps installed in your system.\n",
      "Search for Windows terminal.\n",
      "Update the app and restart your system to  see the changes.\n",
      "For updating the Windows security updates:\n",
      "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
      "Do restart your system once the updates are downloaded and installed successfully.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
      "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
      "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
      "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
      "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How do I use Git / GitHub for this course?\n",
      "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
      "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
      "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
      "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
      "This is also a great resource: https://dangitgit.com/\n",
      "</CONTEXT>\n",
      "\n",
      "<PREVIOUS_ACTIONS>\n",
      "{\"action\": \"SEARCH\", \"reasoning\": \"The question is about succeeding in module 1, but I have no information about the specific requirements or content of the module. I need to search for information on how to succeed in the course, potentially including tips, resources, and expectations for students in module 1.\", \"keywords\": [\"how to succeed in module 1\", \"module 1 tips\", \"module 1 resources\", \"expectations for module 1\", \"course success strategies\"]}\n",
      "</PREVIOUS_ACTIONS>\n",
      "{\n",
      "  \"action\": \"ANSWER\",\n",
      "  \"answer\": \"Unfortunately, the information I have doesn't specify what's needed to succeed specifically in Module 1. However, the course provides resources and materials that you can follow at your own pace. Generally, success involves actively engaging with the course materials, participating in exercises, and seeking help when needed. Make sure to check the course calendar and announcements for specific deadlines and requirements.\",\n",
      "  \"source\": \"OWN_KNOWLEDGE\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"what do I need to do to be successful at module 1?\"\n",
    "\n",
    "search_queries = []\n",
    "search_results = []\n",
    "previous_actions = []\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "while True:\n",
    "    print(f'ITERATION #{iteration}...')\n",
    "\n",
    "    context = build_context(search_results)\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        context=context,\n",
    "        search_queries=\"\\n\".join(search_queries),\n",
    "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
    "        max_iterations=3,\n",
    "        iteration_number=iteration\n",
    "    )\n",
    "\n",
    "    print(prompt)\n",
    "\n",
    "    answer_json = llm(prompt)\n",
    "    answer = json.loads(answer_json)\n",
    "    print(json.dumps(answer, indent=2))\n",
    "\n",
    "    previous_actions.append(answer)\n",
    "\n",
    "    action = answer['action']\n",
    "    if action != 'SEARCH':\n",
    "        break\n",
    "\n",
    "    keywords = answer['keywords']\n",
    "    search_queries = list(set(search_queries) | set(keywords))\n",
    "    \n",
    "    for k in keywords:\n",
    "        res = search(k)\n",
    "        search_results.extend(res)\n",
    "\n",
    "    search_results = dedup(search_results)\n",
    "    \n",
    "    iteration = iteration + 1\n",
    "    if iteration >= 4:\n",
    "        break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5558a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'ANSWER',\n",
       " 'answer': \"Unfortunately, the information I have doesn't specify what's needed to succeed specifically in Module 1. However, the course provides resources and materials that you can follow at your own pace. Generally, success involves actively engaging with the course materials, participating in exercises, and seeking help when needed. Make sure to check the course calendar and announcements for specific deadlines and requirements.\",\n",
       " 'source': 'OWN_KNOWLEDGE'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9549601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, the information I have doesn't specify what's needed to succeed specifically in Module 1. However, the course provides resources and materials that you can follow at your own pace. Generally, success involves actively engaging with the course materials, participating in exercises, and seeking help when needed. Make sure to check the course calendar and announcements for specific deadlines and requirements.\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a328679",
   "metadata": {},
   "source": [
    "### Function calling (\"tool use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff8f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
