{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67b96af-820f-4229-85cc-d61474049f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a75bc1f5-2986-4117-bce6-35ba2ee4b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e0aaf-2458-42fe-b463-efbe1fe615bf",
   "metadata": {},
   "source": [
    "## Quick intro to RAG\n",
    "\n",
    "This is an intro to RAG and also search. We will be using a mini search engine file already created in a previous zoomcamp workshop to boost our solution.\n",
    "\n",
    "### About Minsearch\n",
    "A minimalistic text search engine that uses TF-IDF and cosine similarity for text fields and exact matching for keyword fields. The library provides two implementations:\n",
    "\n",
    "- Index: A basic search index using scikit-learn's TF-IDF vectorizer\n",
    "- AppendableIndex: An appendable search index using an inverted index implementation that allows for incremental document addition\n",
    "\n",
    "To install, use `pip install minsearch`\n",
    "\n",
    "You can view full details of the library [here](https://github.com/alexeygrigorev/minsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ce5c85e-45ec-42fd-ab90-e778e5754180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minsearch is already built in a previous zoomcamp workshop. see link above\n",
    "from minsearch import Index\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706b3ca-cc1f-4444-821b-82f96811461a",
   "metadata": {},
   "source": [
    "### The docs\n",
    "The document used below has also been converted to json for the best outcome. You can create a doc parser to convert documents to json to continue with the below. So we ca start with using requests to fetch the document, convert it to json or pandas dataframe and then a dictionary for final processing.\n",
    "\n",
    "<strong>To dataframe and dict()</strong>\n",
    "- pandas read for csv, tsv, text, excel and json\n",
    "- python-docx for DOCX for Google Docs files\n",
    "- Then `.to_dict()` to convert to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6df720d-f175-43d1-a113-c5b8a530d6b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('./documents.json', 'rt') as f_in:\n",
    "    document = json.load(f_in)\n",
    "\n",
    "docs = []\n",
    "\n",
    "for course in document:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56568adb-8b3b-4522-aef1-f8322820eb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47000780-04cb-4a5e-8501-17861f0e1cbd",
   "metadata": {},
   "source": [
    "### Create and fit the index.\n",
    "- Remember fitting from when you are training an ML model using SKlearn. Yes, that fit.\n",
    "- Fit takes training data as input and learns the necessary parameters or patterns from this data.\n",
    "- Now we initialise the `index` class from minsearch and feed the `docs` above (already parsed as a list) into the index\n",
    "\n",
    "### Boosting and filtering\n",
    "This is used to add weight to the search keys. In the above document we have three keys, text, section, question and there is a course. If we want to prioritise text and question, we use the boost parameter to set that weight. \n",
    "\n",
    "This is similar to when you are defining Algolia search index. Or Elastic search index.\n",
    "\n",
    "Filter helps you to restrict your search responses to a particular set of records.\n",
    "\n",
    "Example: `filter_dict = {\"course\": \"data-engineering-zoomcamp\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fde0b2e-1046-42c3-bc17-051e58ed904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x774cf874bc80>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = Index(\n",
    "    text_fields=[\"text\", \"question\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "index.fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cf74947-b561-494d-b8e1-a59ca67fb230",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_dict = {\"question\": 5, \"text\": 3, \"section\": 1}\n",
    "filter_dict = {\"course\": \"data-engineering-zoomcamp\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccbdef2b-cc80-4e0d-a04f-c534ddf2abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = index.search(\n",
    "    query=query,\n",
    "    boost_dict=boost_dict,\n",
    "    filter_dict=filter_dict,\n",
    "    num_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37293c2c-7a96-47e1-bbbd-8cce90e1b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing an actual search\n",
    "query = \"Can I join the course if it has already started?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d8f24a-136d-4d5c-b445-79f20289ae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c8ecba-244b-489c-8e07-6e60c1d5246c",
   "metadata": {},
   "source": [
    "## Generating answers\n",
    "A quick recap on so far and the journey ahead.\n",
    "\n",
    "- RAG: Is typically a search engine for a corpus of data. For example, FAQ documents or any other document provided. Best to be structured for the best outcome.\n",
    "- LLM: WHen a user sends a query, it hits the search engine which is based on your data. The ouput of the query is usually a lot of responses, these responses are then sent to an LLM to generate a summary of all the responses.\n",
    "\n",
    "Example: When you search for something on Google, there is an AI summary at the top. This is merely a summary of all the links you are about to scroll throguh on the first page of Google.\n",
    "\n",
    "Will be using Gemini insteap of Open AI used during the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "780d53f2-aeab-43da-94a4-613234a82edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "826fdf6b-65d9-46d4-9fa3-72a339a59c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise gemini client\n",
    "client = genai.Client(api_key=\"AIzaSyCWYdzvCfj_Ze1olVtYV-v5z5A_1CkE7vc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b902c7fd-94f4-4a66-a581-087ff253ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template to guide the LLM\n",
    "template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT provided.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "If the CONTEXT doesn't contain the answer, output NOTHING FOUND\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e30eda7e-202f-4932-afe0-9e01f30f60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a context based on the results from the search query executed above\n",
    "# That is, we searched the document and got several results. All results now form our context for the LLM.\n",
    "# For generic cases where we don't know the structure of people's documents, we either would create templates to guide them setting up their instance\n",
    "# or create for them.\n",
    "\n",
    "context = \"\"\n",
    "\n",
    "for doc in results:\n",
    "    context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89f43b42-dad4-40e7-a040-566b2851fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format(question=query, context=context).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6429c7cb-221c-45a4-b53d-91d8f7576cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT provided.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "If the CONTEXT doesn't contain the answer, output NOTHING FOUND\n",
      "\n",
      "QUESTION: Can I join the course if it has already started?\n",
      "\n",
      "CONTEXT: \n",
      "section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I get support if I take the course in the self-paced mode?\n",
      "answer: Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\n",
      "You can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.\n",
      "\n",
      "section: General course-related questions\n",
      "question: How can we contribute to the course?\n",
      "answer: Star the repo! Share it with friends if you find it useful ❣️\n",
      "Create a PR if you see you can improve the text or the structure of the repository.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0dbac4a-5738-44bf-b8df-be9b53482822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ba06df-7da0-4418-b666-2564a88e60be",
   "metadata": {},
   "source": [
    "## Converting it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3be2b-34c5-4748-971e-af16249f1cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46be7629-25db-47cb-8dc5-3062b28f4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the search function\n",
    "def search(query):\n",
    "    boost_dict = {\"question\": 5, \"text\": 3, \"section\": 1}\n",
    "    filter_dict = {\"course\": \"data-engineering-zoomcamp\"}\n",
    "    \n",
    "    results = index.search(\n",
    "    query=query,\n",
    "    boost_dict=boost_dict,\n",
    "    filter_dict=filter_dict,\n",
    "    num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e9da29f-4f82-4088-b792-379b52a647da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT provided.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    If the CONTEXT doesn't contain the answer, output NOTHING FOUND\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\"\n",
    "    \n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = template.format(question=query, context=context).strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92b8c52e-ab31-4425-b424-e2763083efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_response(prompt):\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt\n",
    "    )\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aaa69a2e-a44d-4210-a211-a46fa4252020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    query = query\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm_response(prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68135f37-3fd9-423a-8e6e-e11c2e40200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how long is the course?\"\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm_response(prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "99d86f54-99f4-4a99-b162-fead34cc7c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOTHING FOUND\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
